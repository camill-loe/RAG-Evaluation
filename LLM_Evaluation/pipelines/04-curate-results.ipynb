{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e245108-6319-4b22-beb2-e1c8cbc1b0d5",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "This is a notebook to add additional columns to the result dataframes such as answer_length, product_ai_response_length and vectorsearch_works, which is a boolean that checks whether vectorsearch worked for the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc52bf7-3214-4329-976c-cb9434b07726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "from databricks.vector_search.client import VectorSearchClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f774f-c12d-411a-aae4-2f189f1609f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads in the question_answer_pairs parquet and retrieves the highest timestamp\n",
    "\n",
    "base_folder = \"/Volumes/uc-catalog-dev/advancedanalytics-productai-dev/transformed_dev/llm-evaluation/\" + datetime.now().strftime(\"%Y-%m-%d\") + \"/\"\n",
    "\n",
    "# Get all Question-Answer-Response triplet parquets\n",
    "file_names = [f for f in os.listdir(base_folder) if f.startswith(\"question_answer_pairs+product_ai_answers\") and f.endswith(\".parquet\")]\n",
    "\n",
    "# Retrieve the QAR-triplet parquet with the highest timestamp (most recent run)\n",
    "file_name = max(file_names, key=lambda x: x.split('_')[5].split('.')[0])\n",
    "\n",
    "path = os.path.join(base_folder, file_name)\n",
    "\n",
    "timestamp = file_name.split('_')[5].split('.')[0]\n",
    "print(\"Timestamp:\", timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00580e-14bd-4d94-9824-b49c1e17de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads in the parquet and retrieves the highest timestamp\n",
    "\n",
    "datetime = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "base_folder = f\"/Volumes/uc-catalog-dev/advancedanalytics-productai-dev/transformed_dev/llm-evaluation/{datetime}/\"\n",
    "\n",
    "# Get all of the final parquets\n",
    "file_names = [f for f in os.listdir(base_folder) if f.startswith(\"question_answer_pairs+product_ai_answers+evaluation_results\") and f.endswith(\".parquet\")]\n",
    "\n",
    "# Retrieve parquet with highest timestamp (most recent run)\n",
    "file_name = max(file_names, key=lambda x: x.split('_')[5].split('.')[0])\n",
    "\n",
    "path = os.path.join(base_folder, file_name)\n",
    "\n",
    "timestamp = file_name.split('_')[5].split('.')[0]\n",
    "print(\"Timestamp:\", timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e3131-8b08-418a-ba44-3ff3d8cb4b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_url = os.environ.get(\"WORKSPACE_URL\")\n",
    "sp_client_id = os.environ.get(\"SP_CLIENT_ID\")\n",
    "sp_client_secret = os.environ.get(\"SP_CLIENT_SECRET\")\n",
    "vsc = VectorSearchClient(\n",
    "    workspace_url=workspace_url,\n",
    "    service_principal_client_id=sp_client_id,\n",
    "    service_principal_client_secret=sp_client_secret\n",
    ")\n",
    "index = vsc.get_index(\n",
    "    endpoint_name=\"vectorsearch-dev\",\n",
    "    index_name=\"uc-catalog-dev.advancedanalytics-validationservices-dev.validation_services_index_20240919_085338\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9754dce-a240-4b02-9e6f-602920658147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves the results of vectorsearch for one row\n",
    "def check_document_in_similar_docs(row):\n",
    "    query = row[\"question\"]\n",
    "    document = row[\"document\"]\n",
    "    similar_docs = index.similarity_search(\n",
    "        num_results=10,\n",
    "        columns=[\"text\"],\n",
    "        query_text=query\n",
    "    )\n",
    "    source_titles_and_scores = [\n",
    "        (json.loads(doc[0])['source_title'], doc[1])\n",
    "        for doc in similar_docs['result']['data_array']\n",
    "    ]\n",
    "    source_titles = list(set(title for title, _ in source_titles_and_scores))\n",
    "    similarity_scores = list(set(score for _, score in source_titles_and_scores))\n",
    "    return any(document in source_title for source_title in source_titles), source_titles, similarity_scores\n",
    "\n",
    "# Adds several columns that are important for the visualization of the results\n",
    "def add_columns(df):\n",
    "    df[['vectorsearch_works', 'vectorsearch_source_titles', 'vectorsearch_similarity_scores']] = \\\n",
    "    df.apply(check_document_in_similar_docs, axis=1, result_type='expand')\n",
    "    df['productai_response_time'] = df['productai_response_time'].astype(float)\n",
    "    df['evaluation_score'] = df['evaluation_score'].astype(float)\n",
    "    df['productai_response_length'] = df['productai_response'].apply(len)\n",
    "    df['answer_length'] = df['answer'].apply(len)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada1657-7b7c-4db0-94ed-dd9e56bdf7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(base_folder + f\"question_answer_pairs+productai_answers+evaluation_results_{timestamp}.parquet\")\n",
    "\n",
    "df = add_columns(df)\n",
    "\n",
    "df.to_parquet(base_folder + f\"curated_results_{timestamp}.parquet\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffe71a8-1d6a-4d45-91c9-df98fefd5fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that count the number of tokens generated by LLMs\n",
    "def count_tokens(text):\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    return len(encoding.encode(text))\n",
    "def tokenize_df(df):\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].astype(str).apply(count_tokens)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf40424f-281b-4c93-b7d2-a2dca1db6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df = tokenize_df(df)\n",
    "token_df.to_parquet(base_folder + f\"tokenized_df_{timestamp}.parquet\")\n",
    "display(token_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
