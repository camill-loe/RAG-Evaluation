{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20213a1a-c174-495f-b6be-73319d26ad9b",
   "metadata": {},
   "source": [
    "### Documentation 17.09.2024\n",
    "This script looks for which documents there were generated prompts by Product AI in 02-generate_productai_response. It reads in each of the parquets that were saved previously, which contain the columns question, answer, chunk, document, productai_response. It then evaluates accurate the \"productai_response\" entries are by comparing them to the \"answer\" entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ac215d-d40f-4510-9043-f8f2a0806a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from objects.evaluator import Evaluator\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from langchain_openai.chat_models import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0f5d5b-d6ad-4499-a0f6-4371c402a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads in the question_answer_pairs parquet and retrieves the highest timestamp\n",
    "\n",
    "base_folder = \"/Volumes/uc-catalog-dev/advancedanalytics-productai-dev/transformed_dev/llm-evaluation/\" + datetime.now().strftime(\"%Y-%m-%d\") + \"/\"\n",
    "\n",
    "# Get all Question-Answer-Response triplet parquets\n",
    "file_names = [f for f in os.listdir(base_folder) if f.startswith(\"question_answer_pairs+product_ai_answers\") and f.endswith(\".parquet\")]\n",
    "\n",
    "# Retrieve the QAR-triplet parquet with the highest timestamp (most recent run)\n",
    "file_name = max(file_names, key=lambda x: x.split('_')[5].split('.')[0])\n",
    "\n",
    "path = os.path.join(base_folder, file_name)\n",
    "\n",
    "timestamp = file_name.split('_')[5].split('.')[0]\n",
    "print(\"Timestamp:\", timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9610ae-eaa3-48d5-9780-6ba2eabac392",
   "metadata": {},
   "source": [
    "### Evaluate correctness of ProductAI response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7500e3c2-bfa0-494f-897f-c9fc201b8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(path)\n",
    "model = \"evaluation_gpt4o\"\n",
    "api_key = dbutils.secrets.get(scope='keyvault-link', key='azure-openai-api-key')\n",
    "\n",
    "all_groups = []\n",
    "grouped_df = df.groupby('document')\n",
    "\n",
    "for document, group in tqdm(grouped_df):\n",
    "    doc_scores = []\n",
    "    doc_reasonings = []\n",
    "\n",
    "    # Evaluate the score of the chatbot responses\n",
    "    for _, row in group.iterrows():\n",
    "        evaluator = Evaluator(row['question'], row['answer'], row['productai_response'], model, api_key)\n",
    "        response = evaluator.evaluate_correctness()\n",
    "        doc_scores.append(response['score'])\n",
    "        doc_reasonings.append(response['reasoning'])\n",
    "    \n",
    "    group['evaluation_score'] = doc_scores.astype(float)\n",
    "    group['evaluation_reasoning'] = doc_reasonings\n",
    "    save_path = base_folder + timestamp + f\"/question_answer_pairs+productai_answers+evaluation_results_{document}.parquet\"\n",
    "    group.to_parquet(save_path, index=False)\n",
    "    \n",
    "    all_groups.append(group)\n",
    "\n",
    "# Saving\n",
    "df = pd.concat(all_groups)\n",
    "save_path = base_folder + f\"question_answer_pairs+productai_answers+evaluation_results_{timestamp}.parquet\"\n",
    "df.to_parquet(save_path, index=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a604b4d-f5eb-4d54-ab87-02d7a3f36e68",
   "metadata": {},
   "source": [
    "#### If the code above fails, you can run the code below to keep the progress and start from where you left off\n",
    "#### Make sure to change the variable timestamp to the name of the folder where the progress is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433f3ad-6b2d-4088-bdd6-1ed25941132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp = \"20240928203654\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a3e99-0d08-4408-9126-9ad5e52a6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df = []\n",
    "model = \"evaluation_gpt4o\"\n",
    "api_key = dbutils.secrets.get(scope='keyvault-link', key='azure-openai-api-key')\n",
    "\n",
    "all_groups = []\n",
    "grouped_df = df.groupby('document')\n",
    "\n",
    "# Read in all previously saved dataframes\n",
    "saved_files = [os.path.join(save_folder, timestamp, f) for f in os.listdir(os.path.join(save_folder, timestamp)) \\\n",
    "               if f.startswith('question_answer_pairs+productai_answers+evaluation_results_') and f.endswith('.parquet')]\n",
    "for file in saved_files:\n",
    "    df = pd.read_parquet(file)\n",
    "    all_groups.append(df)\n",
    "    \n",
    "# Get the list of already processed documents\n",
    "processed_docs = [os.path.basename(f).replace('question_answer_pairs_', '').replace('.parquet', '') for f in saved_files]\n",
    "\n",
    "# filter the dataframe on the remaining files\n",
    "remaining_df = grouped_df.filter(lambda x: x.name not in processed_docs)\n",
    "\n",
    "for document, group in tqdm(remaining_df):\n",
    "    doc_scores = []\n",
    "    doc_reasonings = []\n",
    "\n",
    "    # Evaluate the score of the chatbot responses\n",
    "    for _, row in group.iterrows():\n",
    "        evaluator = Evaluator(row['question'], row['answer'], row['productai_response'], model, api_key)\n",
    "        response = evaluator.evaluate_correctness()\n",
    "        doc_scores.append(response['score'])\n",
    "        doc_reasonings.append(response['reasoning'])\n",
    "    \n",
    "    group['evaluation_score'] = doc_scores.astype(float)\n",
    "    group['evaluation_reasoning'] = doc_reasonings\n",
    "    save_path = base_folder + timestamp + f\"/question_answer_pairs+productai_answers+evaluation_results_{document}.parquet\"\n",
    "    group.to_parquet(save_path, index=False)\n",
    "    \n",
    "    all_groups.append(group)\n",
    "\n",
    "# Saving\n",
    "df = pd.concat(all_groups)\n",
    "save_path = base_folder + f\"question_answer_pairs+productai_answers+evaluation_results_{timestamp}.parquet\"\n",
    "df.to_parquet(save_path, index=False)\n",
    "display(df)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
