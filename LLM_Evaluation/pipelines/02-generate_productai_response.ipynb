{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ff999a-3962-4362-9822-aba3d448ced5",
   "metadata": {},
   "source": [
    "### Documentation 17.09.2024\n",
    "This script looks for which documents there were Question-Answer pairs generated today in 01-generate_qa_pairs. For each document it reads in the Question-Answer pairs parquets. Then it goes through each pair and prompts Product AI with the question. It then writes the response into the same folder, where the Question-Answer pair lies.\n",
    "\n",
    "If you want to run this script you will have to update the cookie. To get the cookie follow this process:\n",
    "1. Use Microsoft Edge (also applicable for Firefox, but positional instructions may vary)\n",
    "2. Go to https://app-validation-services-dev.azurewebsites.net/ and login.\n",
    "3. Right click and select \"Untersuchen\" or \"Inspect\" depending on the language.\n",
    "4. Select the \"Netzwerk\" or \"Network\" icon in the top. It looks like the WiFi icon.\n",
    "5. Type in any prompt in the chat, such as \"hello\". On the right, a request will pop up with the name \"chat\".\n",
    "6. Click on the request and in the headers you will find the cookie.\n",
    "7. Copy & paste the cookie into the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e855af5d-adff-4383-ab2b-2bf7f1a129d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cookie = \"<insert_cookie>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc56de-145c-4013-8764-78e97e5430b1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from objects.product_ai_prompter import ProductAIPrompter\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef9007c-28e4-4fd9-9be0-4aad0021236c",
   "metadata": {},
   "source": [
    "### Paths to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2379a0ee-0166-4c49-8b81-dcf4e3783b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads in the question_answer_pairs parquet and retrieves the parquet with the highest timestamp\n",
    "\n",
    "base_folder = \"/Volumes/uc-catalog-dev/advancedanalytics-productai-dev/transformed_dev/llm-evaluation/\" + datetime.now().strftime(\"%Y-%m-%d\") + \"/\"\n",
    "\n",
    "# get all QA-pair parquets\n",
    "file_names = [f for f in os.listdir(base_folder) if f.startswith(\"question_answer_pairs_\") and f.endswith(\".parquet\")]\n",
    "print(\"These are the evaluation sessions from today:\", file_names)\n",
    "\n",
    "# Retrieve the QA-pair parquet with the highest timestamp (most recent run)\n",
    "file_name = max(file_names, key=lambda x: x.split('_')[3].split('.')[0])\n",
    "print(\"This is the current evaluation session:\", file_name)\n",
    "\n",
    "path = os.path.join(base_folder, file_name)\n",
    "\n",
    "timestamp = file_name.split('_')[3].split('.')[0]\n",
    "print(\"Timestamp:\", timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae3c8b-a1cc-477b-9e8a-e06e24ea7a56",
   "metadata": {},
   "source": [
    "### Für Rustam: Der Code hierüber wird wahrscheinlich nicht funktionieren, deswegen habe ich dir den Code hier geschrieben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70bc97a-8fc3-42dc-910b-fef013e03aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"/Volumes/uc-catalog-dev/advancedanalytics-productai-dev/transformed_dev/llm-evaluation/\" + datetime.now().strftime(\"%Y-%m-%d\") + \"/\"\n",
    "path = <hier_den_pfad_des_question_answer_pair_dokumentes_einfügen>\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9979e8b-891f-4e13-a84c-c182a56b621e",
   "metadata": {},
   "source": [
    "### Prompt ProductAI to answer a list of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7d329-1a80-4a80-95b3-a009ad97dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: question 0 is useless because it asked a question on the table of contents which is provided on the first page\n",
    "df = pd.read_parquet(path)\n",
    "prompter = ProductAIPrompter(cookie)\n",
    "\n",
    "grouped_df = df.groupby('document')\n",
    "all_groups = []\n",
    "\n",
    "for document, group in tqdm(grouped_df):\n",
    "    doc_responses = []\n",
    "    doc_response_times = []\n",
    "\n",
    "    # Prompt the chatbot under evaluation with the questions\n",
    "    for _, row in group.iterrows():\n",
    "        question = row['question']\n",
    "        response, response_time = prompter.prompt_productai(question)\n",
    "        doc_responses.append(response)\n",
    "        doc_response_times.append(response_time)\n",
    "    \n",
    "    group['productai_response'] = doc_responses\n",
    "    group['productai_response_time'] = doc_response_times\n",
    "    save_path = base_folder + timestamp + f\"/question_answer_pairs+product_ai_answers_{document}.parquet\"\n",
    "    group.to_parquet(save_path, index=False)\n",
    "    \n",
    "    all_groups.append(group)\n",
    "\n",
    "# Saving\n",
    "df = pd.concat(all_groups)\n",
    "save_path = f\"{base_folder}/question_answer_pairs+product_ai_answers_{timestamp}.parquet\"\n",
    "df.to_parquet(save_path, index=False)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9363ade-9625-4a65-9399-6ad95cbb4483",
   "metadata": {},
   "source": [
    "#### If the code above fails, you can run the code below to keep the progress and start from where you left off\n",
    "#### Make sure to change the variable timestamp to the name of the folder where the progress is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff18a8e9-c28e-4431-b9f3-cc3c8a51aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp = \"20240928203654\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f26d270-9a28-42a3-a1b5-17d0929bbc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df = pd.read_parquet(path)\n",
    "prompter = ProductAIPrompter(cookie)\n",
    "\n",
    "all_groups = []\n",
    "grouped_df = df.groupby('document')\n",
    "\n",
    "# Read in all previously saved dataframes\n",
    "saved_files = [os.path.join(save_folder, timestamp, f) for f in os.listdir(os.path.join(save_folder, timestamp)) \\\n",
    "               if f.startswith('question_answer_pairs+productai_answers') and f.endswith('.parquet')]\n",
    "for file in saved_files:\n",
    "    df = pd.read_parquet(file)\n",
    "    all_groups.append(df)\n",
    "    \n",
    "# Get the list of already processed documents\n",
    "processed_docs = [os.path.basename(f).replace('question_answer_pairs_', '').replace('.parquet', '') for f in saved_files]\n",
    "\n",
    "# filter the dataframe on the remaining files\n",
    "remaining_df = grouped_df.filter(lambda x: x.name not in processed_docs)\n",
    "\n",
    "for document, group in tqdm(remaining_df):\n",
    "    doc_responses = []\n",
    "    doc_response_times = []\n",
    "\n",
    "    # Prompt the chatbot under evaluation with the questions\n",
    "    for _, row in group.iterrows():\n",
    "        question = row['question']\n",
    "        response, response_time = prompter.prompt_productai(question)\n",
    "        doc_responses.append(response)\n",
    "        doc_response_times.append(response_time)\n",
    "    \n",
    "    group['productai_response'] = doc_responses\n",
    "    group['productai_response_time'] = doc_response_times\n",
    "    save_path = base_folder + timestamp + f\"/question_answer_pairs+product_ai_answers_{document}.parquet\"\n",
    "    group.to_parquet(save_path, index=False)\n",
    "    \n",
    "    all_groups.append(group)\n",
    "\n",
    "# Saving\n",
    "df = pd.concat(all_groups)\n",
    "save_path = f\"{base_folder}/question_answer_pairs+product_ai_answers_{timestamp}.parquet\"\n",
    "df.to_parquet(save_path, index=False)\n",
    "display(df)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
